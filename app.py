import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import tempfile
import os
import base64
import time
import glob
import re
from st_aggrid import AgGrid, GridOptionsBuilder, JsCode
from io import BytesIO
from pathlib import Path
from functools import lru_cache
from typing import List, Dict, Optional

# ==========================================
# üîê –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø
# ==========================================
st.set_page_config(
    layout="wide",
    page_title="Drawing Review",
    page_icon="üèóÔ∏è",
    initial_sidebar_state="expanded"
)

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CSS
def hide_branding():
    st.markdown("""
        <style>
            /* [class^="..."] –æ–∑–Ω–∞—á–∞—î "–∫–ª–∞—Å, —â–æ –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑..." */
            div[class^="_profilePreview"] {
                display: none !important;
            }
        </style>
    """, unsafe_allow_html=True)
    # hide_styles = """
    #     <style>
    #         ._profilePreview_gzau3_63 {
    #             display: none !important;
    #         }
    #     </style>
    # """
    # st.markdown(hide_styles, unsafe_allow_html=True)

hide_branding()

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏
RULES_DIR = "rules"
MAX_RETRIES = 3
RETRY_DELAY = 2

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è API
@st.cache_resource
def init_genai():
    """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î Gemini API –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º."""
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        st.error("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ API –∫–ª—é—á —É secrets.toml")
        st.stop()
    
    try:
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó API: {e}")
        st.stop()

init_genai()

# ==========================================
# üõ†Ô∏è –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á
# ==========================================

def display_pdf(file_path: str) -> None:
    """–í—ñ–¥–æ–±—Ä–∞–∂–∞—î PDF —É –±—Ä–∞—É–∑–µ—Ä—ñ —á–µ—Ä–µ–∑ iframe –∑ —Ñ—ñ–∫—Å–æ–º –¥–ª—è Chrome."""
    try:
        with open(file_path, "rb") as f:
            pdf_bytes = f.read()
            base64_pdf = base64.b64encode(pdf_bytes).decode('utf-8')
        
        # –î–æ–¥–∞—î–º–æ MIME type —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è Chrome
        pdf_display = f'''
            <iframe 
                src="data:application/pdf;base64,{base64_pdf}#toolbar=1&navpanes=0&scrollbar=1" 
                width="100%" 
                height="800" 
                type="application/pdf"
                style="border: none;">
                <p>–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î –≤–±—É–¥–æ–≤–∞–Ω–∏–π –ø–µ—Ä–µ–≥–ª—è–¥ PDF. 
                   <a href="data:application/pdf;base64,{base64_pdf}" download="drawing.pdf">–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª</a>
                </p>
            </iframe>
        '''
        st.markdown(pdf_display, unsafe_allow_html=True)
        
        # –î–æ–¥–∞—î–º–æ –∫–Ω–æ–ø–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —è–∫ –∑–∞–ø–∞—Å–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.download_button(
                label="üì• –Ø–∫—â–æ PDF –Ω–µ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—î—Ç—å—Å—è - –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª",
                data=pdf_bytes,
                file_name="drawing.pdf",
                mime="application/pdf",
                help="Chrome –º–æ–∂–µ –±–ª–æ–∫—É–≤–∞—Ç–∏ –≤–±—É–¥–æ–≤–∞–Ω–∏–π –ø–µ—Ä–µ–≥–ª—è–¥ PDF"
            )
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è PDF: {e}")
        # –§–æ–ª–ª–±–µ–∫ - –∫–Ω–æ–ø–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        try:
            with open(file_path, "rb") as f:
                st.download_button(
                    label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ PDF",
                    data=f.read(),
                    file_name="drawing.pdf",
                    mime="application/pdf"
                )
        except:
            st.error("–ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–∞–π–ª")

def clean_json_text(text: str) -> str:
    """–û—á–∏—â–∞—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å AI –≤—ñ–¥ –∑–∞–π–≤–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤ markdown."""
    text = text.strip()
    # –í–∏–¥–∞–ª—è—î–º–æ markdown –±–ª–æ–∫–∏
    if text.startswith("```json"):
        text = text[7:]
    elif text.startswith("```"):
        text = text[3:]
    if text.endswith("```"):
        text = text[:-3]
    return text.strip()

@lru_cache(maxsize=32)
def load_json_file(file_path: str) -> Optional[Dict]:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î JSON —Ñ–∞–π–ª –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.sidebar.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è {Path(file_path).name}: {e}")
        return None

def load_rules_from_json(selected_files: List[str]) -> str:
    """–ó—á–∏—Ç—É—î –≤–∏–±—Ä–∞–Ω—ñ JSON —Ñ–∞–π–ª–∏ —ñ —Ñ–æ—Ä–º—É—î —î–¥–∏–Ω–∏–π —Ç–µ–∫—Å—Ç–æ–≤–∏–π —Ä—è–¥–æ–∫ –ø—Ä–∞–≤–∏–ª."""
    combined_rules = ""
    for file_path in selected_files:
        data = load_json_file(file_path)
        if data:
            filename = Path(file_path).name
            combined_rules += f"\n--- SOURCE: {filename} ---\n"
            combined_rules += json.dumps(data, indent=2, ensure_ascii=False)
            combined_rules += "\n"
    return combined_rules

def to_excel(df: pd.DataFrame) -> bytes:
    """–ö–æ–Ω–≤–µ—Ä—Ç—É—î DataFrame –≤ Excel —Ñ–∞–π–ª —É –ø–∞–º'—è—Ç—ñ."""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Analysis Results')
        # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
        worksheet = writer.sheets['Analysis Results']
        for idx, col in enumerate(df.columns):
            max_length = max(
                df[col].astype(str).str.len().max(),
                len(col)
            )
            worksheet.column_dimensions[chr(65 + idx)].width = min(max_length + 2, 50)
    return output.getvalue()

def upload_file_with_retry(file_path: str, mime_type: str = "application/pdf"):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ñ–∞–π–ª –≤ Gemini –∑ –ø–æ–≤—Ç–æ—Ä–Ω–∏–º–∏ —Å–ø—Ä–æ–±–∞–º–∏."""
    for attempt in range(MAX_RETRIES):
        try:
            uploaded_file = genai.upload_file(file_path, mime_type=mime_type)
            
            # –ß–µ–∫–∞—î–º–æ –æ–±—Ä–æ–±–∫–∏
            timeout = 60  # —Å–µ–∫—É–Ω–¥
            start_time = time.time()
            while uploaded_file.state.name == "PROCESSING":
                if time.time() - start_time > timeout:
                    raise TimeoutError("–ü–µ—Ä–µ–≤–∏—â–µ–Ω–æ —á–∞—Å –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É")
                time.sleep(1)
                uploaded_file = genai.get_file(uploaded_file.name)
            
            if uploaded_file.state.name == "FAILED":
                raise ValueError("–ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ PDF –Ω–∞ —Å—Ç–æ—Ä–æ–Ω—ñ Google")
            
            return uploaded_file
            
        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                st.warning(f"‚ö†Ô∏è –°–ø—Ä–æ–±–∞ {attempt + 1}/{MAX_RETRIES} –Ω–µ –≤–¥–∞–ª–∞—Å—è. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {RETRY_DELAY}—Å...")
                time.sleep(RETRY_DELAY)
            else:
                raise e

def analyze_pdf_drawing(file_path: str, rules_text: str, model_name: str) -> str:
    """–í—ñ–¥–ø—Ä–∞–≤–ª—è—î PDF –≤ Gemini —ñ –ø–æ–≤–µ—Ä—Ç–∞—î —Ç–µ–∫—Å—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ."""
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É
    with st.spinner("üì§ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É..."):
        uploaded_file_ref = upload_file_with_retry(file_path)
    
    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç—É
    prompt = f"""
Role: Lead Quality Control Engineer with expertise in technical documentation standards.

Task: Analyze this technical drawing PDF against the specific Ruleset provided below. 
Identify ALL violations, inconsistencies, and areas of non-compliance.

ACTIVE RULESET (Strictly follow these requirements):
{rules_text}

Instructions:
1. Check each page systematically
2. Identify specific components with issues
3. Provide actionable fix recommendations
4. Assess criticality (High/Medium/Low)

Output Format:
Return ONLY a valid JSON array. No markdown, no explanations.
Example:
[
    {{
        "page": 1,
        "component": "Shaft Detail A",
        "issue": "Missing tolerance specification per ISO 286-1",
        "fix": "Add tolerance class h7 to diameter 25mm",
        "criticality": "High"
    }}
]

If no issues found, return: []
"""
    
    # –í–∏–∫–ª–∏–∫ –º–æ–¥–µ–ª—ñ
    model = genai.GenerativeModel(model_name)
    
    with st.spinner("ü§ñ AI –∞–Ω–∞–ª—ñ–∑—É—î –∫—Ä–µ—Å–ª–µ–Ω–Ω—è..."):
        response = model.generate_content(
            [prompt, uploaded_file_ref],
            generation_config={
                "response_mime_type": "application/json",
                "temperature": 0.1,  # –ù–∏–∑—å–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ
            }
        )
    
    # –í–∏–¥–∞–ª–µ–Ω–Ω—è —Ñ–∞–π–ª—É –∑ —Å–µ—Ä–≤–µ—Ä–∞ Google
    try:
        genai.delete_file(uploaded_file_ref.name)
    except:
        pass
    
    return response.text

# ==========================================
# üõ†Ô∏è –§–£–ù–ö–¶–Ü–á –î–õ–Ø –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø CSV
# ==========================================

def parse_csv_value(value_str: str) -> str:
    """–ü–∞—Ä—Å–∏—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è –∑ JSON-like —Ñ–æ—Ä–º–∞—Ç—É CSV."""
    try:
        # –í–∏–¥–∞–ª—è—î–º–æ –∑–∞–π–≤—ñ –ª–∞–ø–∫–∏ —Ç–∞ –ø–∞—Ä—Å–∏–º–æ JSON
        cleaned = value_str.strip('"')
        if cleaned.startswith('{"Value":'):
            data = json.loads(cleaned)
            return data.get("Value", "")
        return cleaned
    except:
        return value_str

def load_csv_file(uploaded_file) -> pd.DataFrame:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î CSV —Ñ–∞–π–ª —ñ –ø–∞—Ä—Å–∏—Ç—å –π–æ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É."""
    try:
        # –ß–∏—Ç–∞—î–º–æ CSV
        df = pd.read_csv(uploaded_file, sep=';', encoding='utf-8-sig')
        
        # –ü–∞—Ä—Å–∏–º–æ –∫–æ–∂–Ω—É –∫–æ–ª–æ–Ω–∫—É
        for col in df.columns:
            df[col] = df[col].apply(parse_csv_value)
        
        return df
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è CSV: {e}")
        return None

def extract_date_from_filename(filename: str) -> str:
    """–í–∏—Ç—è–≥—É—î –¥–∞—Ç—É –∑ –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É."""
    # –®—É–∫–∞—î–º–æ –ø–∞—Ç—Ç–µ—Ä–Ω –¥–∞—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç—ñ YYYY-MM-DD –∞–±–æ –ø–æ–¥—ñ–±–Ω–æ–º—É
    match = re.search(r'(\d{4}[-_]\d{2}[-_]\d{2})', filename)
    if match:
        return match.group(1)
    return ""

def compare_csv_files(df1: pd.DataFrame, df2: pd.DataFrame, file1_name: str, file2_name: str) -> Dict:
    """–ü–æ—Ä—ñ–≤–Ω—é—î –¥–≤–∞ CSV —Ñ–∞–π–ª–∏ —ñ –ø–æ–≤–µ—Ä—Ç–∞—î —Ä—ñ–∑–Ω–∏—Ü—ñ."""
    
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ, —è–∫–∏–π —Ñ–∞–π–ª –Ω–æ–≤—ñ—à–∏–π
    date1 = extract_date_from_filename(file1_name)
    date2 = extract_date_from_filename(file2_name)
    
    if date2 > date1:
        old_df, new_df = df1, df2
        old_name, new_name = file1_name, file2_name
    else:
        old_df, new_df = df2, df1
        old_name, new_name = file2_name, file1_name
    
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ full_path —è–∫ –∫–ª—é—á –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
    old_paths = set(old_df['full_path'].values)
    new_paths = set(new_df['full_path'].values)
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —Ä—ñ–∑–Ω–∏—Ü—ñ
    added_files = new_paths - old_paths
    deleted_files = old_paths - new_paths
    common_files = old_paths & new_paths
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∑–º—ñ–Ω–µ–Ω—ñ —Ñ–∞–π–ª–∏ (–¥–µ –∑–º—ñ–Ω–∏–ª–∏—Å—å –¥–∞—Ç–∏)
    modified_files = []
    for path in common_files:
        old_row = old_df[old_df['full_path'] == path].iloc[0]
        new_row = new_df[new_df['full_path'] == path].iloc[0]
        
        if 'last_modif' in old_df.columns and 'last_modif' in new_df.columns:
            if old_row['last_modif'] != new_row['last_modif']:
                modified_files.append(path)
    
    return {
        'added': list(added_files),
        'deleted': list(deleted_files),
        'modified': modified_files,
        'old_name': old_name,
        'new_name': new_name
    }

def create_copy_button(file_path: str, key_suffix: str):
    """–°—Ç–≤–æ—Ä—é—î –∫–Ω–æ–ø–∫—É –¥–ª—è –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è —à–ª—è—Ö—É —Ñ–∞–π–ª—É."""
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –¥–æ Windows —Ñ–æ—Ä–º–∞—Ç—É —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
    windows_path = file_path.replace('/', '\\')
    
    # HTML –¥–ª—è –∫–Ω–æ–ø–∫–∏ –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è
    copy_btn = f"""
        <button onclick="navigator.clipboard.writeText('{windows_path}').then(() => {{
            this.innerHTML = '‚úÖ –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ!';
            setTimeout(() => {{ this.innerHTML = 'üìã –ö–æ–ø—ñ—é–≤–∞—Ç–∏'; }}, 2000);
        }})" 
        style="padding: 4px 12px; 
               background-color: #4CAF50; 
               color: white; 
               border: none; 
               border-radius: 4px; 
               cursor: pointer;
               font-size: 12px;
               margin-left: 10px;">
            üìã –ö–æ–ø—ñ—é–≤–∞—Ç–∏
        </button>
    """
    
    st.markdown(f"{file_path} {copy_btn}", unsafe_allow_html=True)

# ==========================================
# üñ•Ô∏è –û–°–ù–û–í–ù–ò–ô –Ü–ù–¢–ï–†–§–ï–ô–°
# ==========================================

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è session_state
if 'analysis_df' not in st.session_state:
    st.session_state.analysis_df = None
if 'last_uploaded_filename' not in st.session_state:
    st.session_state.last_uploaded_filename = None
if 'selected_model' not in st.session_state:
    st.session_state.selected_model = "gemini-1.5-flash"  # –ë–µ–∑–ø–µ—á–Ω–∏–π —Ñ–æ–ª–ª–±–µ–∫

# --- –°–∞–π–¥–±–∞—Ä ---
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
    @st.cache_data(ttl=3600)  # –ö–µ—à—É—î–º–æ –Ω–∞ 1 –≥–æ–¥–∏–Ω—É
    def get_available_models():
        """–û—Ç—Ä–∏–º—É—î —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –∑ API."""
        try:
            models = genai.list_models()
            available = {}
            for model in models:
                if 'generateContent' in model.supported_generation_methods:
                    model_name = model.name.replace('models/', '')
                    # –°—Ç–≤–æ—Ä—é—î–º–æ —á–∏—Ç–∞–±–µ–ª—å–Ω—ñ –Ω–∞–∑–≤–∏
                    if 'gemini-3' in model_name.lower():
                        display_name = f"üî• {model_name} (Gemini 3)"
                    elif 'gemini-2.5' in model_name.lower():
                        display_name = f"‚ö° {model_name} (Gemini 2.5)"
                    elif 'gemini-2.0' in model_name.lower():
                        display_name = f"üí® {model_name} (Gemini 2.0)"
                    elif 'gemini-1.5-pro' in model_name.lower():
                        display_name = f"üéØ {model_name} (Gemini 1.5 Pro)"
                    elif 'gemini-1.5-flash' in model_name.lower():
                        display_name = f"‚ö° {model_name} (Gemini 1.5 Flash)"
                    else:
                        display_name = model_name
                    
                    available[model_name] = display_name
            return available
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π: {e}")
            # –§–æ–ª–ª–±–µ–∫ –Ω–∞ –±–∞–∑–æ–≤—É –º–æ–¥–µ–ª—å
            return {"gemini-1.5-flash": "‚ö° gemini-1.5-flash (Gemini 1.5 Flash)"}
    
    # –û—Ç—Ä–∏–º—É—î–º–æ –¥–æ—Å—Ç—É–ø–Ω—ñ –º–æ–¥–µ–ª—ñ
    available_models = get_available_models()
    
    # –í–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ
    if available_models:
        model_options = list(available_models.keys())
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —ñ–Ω–¥–µ–∫—Å –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
        default_index = 0
        if st.session_state.selected_model in model_options:
            default_index = model_options.index(st.session_state.selected_model)
        elif 'gemini-2.5-flash' in model_options:
            default_index = model_options.index('gemini-2.5-flash')
        elif 'gemini-1.5-flash' in model_options:
            default_index = model_options.index('gemini-1.5-flash')
        
        selected_model = st.selectbox(
            "ü§ñ –ú–æ–¥–µ–ª—å AI:",
            options=model_options,
            format_func=lambda x: available_models[x],
            index=default_index,
            key="model_selector",
            help="–û–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –∫—Ä–µ—Å–ª–µ–Ω—å"
        )
        st.session_state.selected_model = selected_model
        
        # –ü–æ–∫–∞–∑—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
        st.caption(f"üìä –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(available_models)}")
    else:
        st.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—ñ")
        st.session_state.selected_model = "gemini-1.5-flash"
    
    st.divider()
    st.header("üìö –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ –°—Ç–∞–Ω–¥–∞—Ä—Ç—ñ–≤")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤ —á–µ—Ä–µ–∑ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    st.caption("–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Ñ–∞–π–ª–∏:")
    uploaded_json_files = st.file_uploader(
        "–û–±–µ—Ä—ñ—Ç—å JSON —Ñ–∞–π–ª–∏",
        type=["json"],
        accept_multiple_files=True,
        help="–î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø—Ä–∞–≤–∏–ª–∞, —è–∫—ñ –¥–æ–ø–æ–≤–Ω—è—Ç—å —Ñ–∞–π–ª–∏ –∑ –ø–∞–ø–∫–∏ rules/",
        key="json_uploader"
    )
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —Ñ–∞–π–ª–∏ –≤ session_state
    if uploaded_json_files:
        if 'uploaded_rules_files' not in st.session_state:
            st.session_state.uploaded_rules_files = {}
        
        for uploaded_file in uploaded_json_files:
            st.session_state.uploaded_rules_files[uploaded_file.name] = uploaded_file.getvalue()
    
    st.divider()
    
    # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ —Ñ–∞–π–ª–∏
    all_files = {}
    
    # 1. –õ–æ–∫–∞–ª—å–Ω—ñ —Ñ–∞–π–ª–∏ –∑ –ø–∞–ø–∫–∏ rules/
    Path(RULES_DIR).mkdir(exist_ok=True)
    local_json_files = list(Path(RULES_DIR).glob("*.json"))
    for file_path in local_json_files:
        all_files[f"local:{file_path.name}"] = {
            "name": file_path.name,
            "path": str(file_path),
            "source": "üìÅ –õ–æ–∫–∞–ª—å–Ω—ñ",
            "default": True  # –õ–æ–∫–∞–ª—å–Ω—ñ —Ñ–∞–π–ª–∏ –≤–∫–ª—é—á–µ–Ω—ñ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
        }
    
    # 2. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —Ñ–∞–π–ª–∏
    if 'uploaded_rules_files' in st.session_state:
        for file_name, file_content in st.session_state.uploaded_rules_files.items():
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª
            temp_path = Path(tempfile.gettempdir()) / f"uploaded_{file_name}"
            temp_path.write_bytes(file_content)
            
            all_files[f"upload:{file_name}"] = {
                "name": file_name,
                "path": str(temp_path),
                "source": "‚òÅÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ",
                "default": False  # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –Ω–µ –≤–∫–ª—é—á–µ–Ω—ñ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
            }
    
    # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö —Ñ–∞–π–ª—ñ–≤
    selected_files = []
    
    if all_files:
        st.caption("–û–±–µ—Ä—ñ—Ç—å —Ñ–∞–π–ª–∏ –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:")
        
        # –ì—Ä—É–ø—É—î–º–æ –ø–æ –¥–∂–µ—Ä–µ–ª—É –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        local_files = {k: v for k, v in all_files.items() if v["source"] == "üìÅ –õ–æ–∫–∞–ª—å–Ω—ñ"}
        uploaded_files = {k: v for k, v in all_files.items() if v["source"] == "‚òÅÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ"}
        
        # –õ–æ–∫–∞–ª—å–Ω—ñ —Ñ–∞–π–ª–∏
        if local_files:
            st.markdown("**üìÅ –§–∞–π–ª–∏ –∑ –ø–∞–ø–∫–∏ rules/ (–≤–∫–ª—é—á–µ–Ω—ñ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º):**")
            for key, file_info in local_files.items():
                if st.checkbox(
                    f"{file_info['name']}",
                    value=file_info['default'],
                    key=f"cb_{key}",
                    help=f"–î–∂–µ—Ä–µ–ª–æ: {file_info['source']}"
                ):
                    selected_files.append(file_info['path'])
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —Ñ–∞–π–ª–∏
        if uploaded_files:
            st.markdown("**‚òÅÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —Ñ–∞–π–ª–∏:**")
            for key, file_info in uploaded_files.items():
                if st.checkbox(
                    f"{file_info['name']}",
                    value=file_info['default'],
                    key=f"cb_{key}",
                    help=f"–î–∂–µ—Ä–µ–ª–æ: {file_info['source']}"
                ):
                    selected_files.append(file_info['path'])
    else:
        st.info("üìÇ –§–∞–π–ª—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –î–æ–¥–∞–π—Ç–µ JSON –≤ –ø–∞–ø–∫—É rules/ –∞–±–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —á–µ—Ä–µ–∑ —Ñ–æ—Ä–º—É –≤–∏—â–µ")
    
    # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
    if 'uploaded_rules_files' in st.session_state and st.session_state.uploaded_rules_files:
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —Ñ–∞–π–ª–∏"):
            st.session_state.uploaded_rules_files = {}
            st.rerun()

    st.divider()
    
    # –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–≥–ª—è–¥ –ø—Ä–∞–≤–∏–ª
    if selected_files:
        st.subheader("üëÄ –ê–∫—Ç–∏–≤–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞")
        with st.expander(f"üîç {len(selected_files)} —Ñ–∞–π–ª(—ñ–≤) –≤–∏–±—Ä–∞–Ω–æ"):
            active_rules_preview = load_rules_from_json(selected_files)
            st.code(active_rules_preview, language="json")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_chars = len(active_rules_preview)
        st.caption(f"üìä –†–æ–∑–º—ñ—Ä –ø—Ä–æ–º–ø—Ç—É: ~{total_chars:,} —Å–∏–º–≤–æ–ª—ñ–≤")
    else:
        st.warning("‚ö†Ô∏è –ù–µ –≤–∏–±—Ä–∞–Ω–æ –∂–æ–¥–Ω–æ–≥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É!")

# ==========================================
# –ì–û–õ–û–í–ù–ï –ú–ï–ù–Æ (–¢–ê–ë–ò)
# ==========================================

main_tab1, main_tab2 = st.tabs(["üîç Check", "‚öñÔ∏è Compare"])

# ==========================================
# TAB 1: CHECK (—ñ—Å–Ω—É—é—á–∏–π —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª)
# ==========================================
with main_tab1:
    uploaded_file = st.file_uploader(
        "üìé –ó–∞–≤–∞–Ω—Ç–∞–∂ PDF –∫—Ä–µ—Å–ª–µ–Ω–Ω—è",
        type=["pdf"],
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å Streamlit",
        key="pdf_uploader"
    )

    # –û—á–∏—â–∞—î–º–æ —Å—Ç–∞—Ä—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
    if uploaded_file and uploaded_file.name != st.session_state.last_uploaded_filename:
        st.session_state.analysis_df = None
        st.session_state.last_uploaded_filename = uploaded_file.name

    if uploaded_file:
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name

        # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
        tab1, tab2 = st.tabs(["üìÑ –ü–µ—Ä–µ–≥–ª—è–¥", "ü§ñ –ê–Ω–∞–ª—ñ–∑"])
        
        with tab1:
            display_pdf(tmp_file_path)
        
        with tab2:
            st.subheader("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏")
            
            col1, col2 = st.columns([3, 1])
            with col1:
                btn_disabled = len(selected_files) == 0
                analyze_btn = st.button(
                    "üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –ø–µ—Ä–µ–≤—ñ—Ä–∫—É",
                    type="primary",
                    disabled=btn_disabled,
                    use_container_width=True
                )
            with col2:
                if st.session_state.analysis_df is not None:
                    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç–∏", use_container_width=True):
                        st.session_state.analysis_df = None
                        st.rerun()
            
            if analyze_btn:
                st.session_state.analysis_df = None
                
                try:
                    final_rules_text = load_rules_from_json(selected_files)
                    raw_response = analyze_pdf_drawing(
                        tmp_file_path,
                        final_rules_text,
                        st.session_state.selected_model
                    )
                    
                    json_response = clean_json_text(raw_response)
                    data = json.loads(json_response)

                    if not data:
                        st.success("‚úÖ –ß—É–¥–æ–≤–æ! AI –Ω–µ –∑–Ω–∞–π—à–æ–≤ –∂–æ–¥–Ω–∏—Ö –ø–æ—Ä—É—à–µ–Ω—å –≤–∏–±—Ä–∞–Ω–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ñ–≤.")
                    else:
                        st.session_state.analysis_df = pd.DataFrame(data)
                        st.success(f"‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ó–Ω–∞–π–¥–µ–Ω–æ {len(data)} –Ω–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç–µ–π.")

                except json.JSONDecodeError as e:
                    st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É JSON: {e}")
                    with st.expander("üêõ Debug Info"):
                        st.code(json_response if 'json_response' in locals() else raw_response)
                except Exception as e:
                    st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É: {e}")
                    with st.expander("üêõ –î–µ—Ç–∞–ª—ñ –ø–æ–º–∏–ª–∫–∏"):
                        st.exception(e)

            if btn_disabled:
                st.error("üëà –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–∏–±–µ—Ä–∏ —Ö–æ—á–∞ –± –æ–¥–∏–Ω —Ñ–∞–π–ª —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ñ–≤ —É –º–µ–Ω—é –∑–ª—ñ–≤–∞!")

            # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            if st.session_state.analysis_df is not None:
                df = st.session_state.analysis_df
                
                # –ú–µ—Ç—Ä–∏–∫–∏
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–í—Å—å–æ–≥–æ –ø—Ä–æ–±–ª–µ–º", len(df))
                with col2:
                    high_count = len(df[df['criticality'] == 'High']) if 'criticality' in df.columns else 0
                    st.metric("–ö—Ä–∏—Ç–∏—á–Ω–∏—Ö", high_count, delta=None, delta_color="inverse")
                with col3:
                    unique_pages = df['page'].nunique() if 'page' in df.columns else 0
                    st.metric("–°—Ç–æ—Ä—ñ–Ω–æ–∫ –∑ –ø—Ä–æ–±–ª–µ–º–∞–º–∏", unique_pages)
                
                st.divider()
                
                # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ
                gb = GridOptionsBuilder.from_dataframe(df)
                gb.configure_default_column(
                    resizable=True,
                    wrapText=True,
                    autoHeight=True,
                    sortable=True,
                    filter=True
                )
                
                # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫
                if 'issue' in df.columns:
                    gb.configure_column("issue", width=400)
                if 'fix' in df.columns:
                    gb.configure_column("fix", width=400)
                if 'component' in df.columns:
                    gb.configure_column("component", width=200)
                if 'page' in df.columns:
                    gb.configure_column("page", width=80)
                if 'criticality' in df.columns:
                    gb.configure_column("criticality", width=120)
                    
                    # –ö–æ–ª—ñ—Ä –¥–ª—è criticality
                    jscode = JsCode("""
                    function(params) {
                        if (params.value === 'High') {
                            return {'color': 'white', 'backgroundColor': '#dc3545', 'fontWeight': 'bold'};
                        }
                        if (params.value === 'Medium') {
                            return {'color': 'black', 'backgroundColor': '#ffc107'};
                        }
                        if (params.value === 'Low') {
                            return {'color': 'black', 'backgroundColor': '#28a745', 'color': 'white'};
                        }
                        return {'color': 'black', 'backgroundColor': 'white'};
                    };
                    """)
                    gb.configure_column("criticality", cellStyle=jscode)
                
                gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=20)
                gb.configure_selection(selection_mode="multiple", use_checkbox=True)
                
                gridOptions = gb.build()

                grid_response = AgGrid(
                    df,
                    gridOptions=gridOptions,
                    height=500,
                    allow_unsafe_jscode=True,
                    enable_enterprise_modules=False,
                    theme="streamlit",
                    key='analysis_grid',
                    reload_data=False
                )

                # –ï–∫—Å–ø–æ—Ä—Ç
                st.divider()
                col1, col2 = st.columns(2)
                
                with col1:
                    excel_data = to_excel(df)
                    st.download_button(
                        label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Excel",
                        data=excel_data,
                        file_name=f"analysis_{Path(uploaded_file.name).stem}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
                
                with col2:
                    csv_data = df.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ CSV",
                        data=csv_data,
                        file_name=f"analysis_{Path(uploaded_file.name).stem}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )

        # –í–∏–¥–∞–ª—è—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª –ø—Ä–∏ –≤–∏—Ö–æ–¥—ñ
        try:
            os.unlink(tmp_file_path)
        except:
            pass

    else:
        st.info("üëÜ –ó–∞–≤–∞–Ω—Ç–∞–∂ PDF –∫—Ä–µ—Å–ª–µ–Ω–Ω—è, —â–æ–± –ø–æ—á–∞—Ç–∏ —Ä–æ–±–æ—Ç—É")
        # –û—á–∏—â–∞—î–º–æ —Å—Ç–∞–Ω –ø—Ä–∏ –≤—ñ–¥—Å—É—Ç–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—É
        st.session_state.analysis_df = None
        st.session_state.last_uploaded_filename = None

# ==========================================
# TAB 2: COMPARE (–Ω–æ–≤–∏–π —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª)
# ==========================================
with main_tab2:
    st.subheader("‚öñÔ∏è –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤ CSV")
    st.caption("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –¥–≤–∞ CSV —Ñ–∞–π–ª–∏ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑–º—ñ–Ω —É —Ñ–∞–π–ª–æ–≤—ñ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ")
    
    # –û–¥–Ω–∞ –∫–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è 2—Ö —Ñ–∞–π–ª—ñ–≤
    csv_files = st.file_uploader(
        "üìÇ –û–±–µ—Ä—ñ—Ç—å 2 CSV —Ñ–∞–π–ª–∏ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è",
        type=["csv"],
        accept_multiple_files=True,
        key="csv_files",
        # help="–í–∏–±–µ—Ä—ñ—Ç—å —Ä—ñ–≤–Ω–æ 2 CSV —Ñ–∞–π–ª–∏ –∑ –æ–¥–Ω—ñ—î—ó –ø–∞–ø–∫–∏"
    )
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Ñ–∞–π–ª—ñ–≤
    if csv_files and len(csv_files) == 2:
        csv_file1, csv_file2 = csv_files[0], csv_files[1]
        
        with st.spinner("üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤..."):
                # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –æ–±–∏–¥–≤–∞ —Ñ–∞–π–ª–∏
                df1 = load_csv_file(csv_file1)
                df2 = load_csv_file(csv_file2)
                
                if df1 is not None and df2 is not None:
                    # –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ —Ñ–∞–π–ª–∏
                    comparison = compare_csv_files(df1, df2, csv_file1.name, csv_file2.name)
                    
                    # –í—ñ–¥–æ–±—Ä–∞–∂–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ–∞–π–ª–∏
                    st.success("‚úÖ –§–∞–π–ª–∏ —É—Å–ø—ñ—à–Ω–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ!")
                    
                    info_col1, info_col2 = st.columns(2)
                    with info_col1:
                        st.info(f"üìÖ **–°—Ç–∞—Ä—ñ—à–∏–π —Ñ–∞–π–ª:** {comparison['old_name']}")
                    with info_col2:
                        st.info(f"üìÖ **–ù–æ–≤—ñ—à–∏–π —Ñ–∞–π–ª:** {comparison['new_name']}")
                
                st.divider()
                
                # –ú–µ—Ç—Ä–∏–∫–∏
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("üÜï –ù–æ–≤—ñ —Ñ–∞–π–ª–∏", len(comparison['added']))
                with metric_col2:
                    st.metric("‚úèÔ∏è –ó–º—ñ–Ω–µ–Ω—ñ —Ñ–∞–π–ª–∏", len(comparison['modified']))
                with metric_col3:
                    st.metric("üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω—ñ —Ñ–∞–π–ª–∏", len(comparison['deleted']))
                
                st.divider()
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∞–±–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                result_tab1, result_tab2, result_tab3 = st.tabs([
                    f"üÜï –ù–æ–≤—ñ —Ñ–∞–π–ª–∏ ({len(comparison['added'])})",
                    f"‚úèÔ∏è –ó–º—ñ–Ω–µ–Ω—ñ —Ñ–∞–π–ª–∏ ({len(comparison['modified'])})",
                    f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω—ñ —Ñ–∞–π–ª–∏ ({len(comparison['deleted'])})"
                ])
                
                # –¢–∞–± 1: –ù–æ–≤—ñ —Ñ–∞–π–ª–∏
                with result_tab1:
                    if comparison['added']:
                        st.subheader("–°–ø–∏—Å–æ–∫ –Ω–æ–≤–∏—Ö —Ñ–∞–π–ª—ñ–≤")
                        for idx, file_path in enumerate(sorted(comparison['added']), 1):
                            st.text(f"{idx}.")
                            st.code(file_path.replace('/', '\\'), language=None)
                    else:
                        st.info("‚úÖ –ù–æ–≤–∏—Ö —Ñ–∞–π–ª—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                
                # –¢–∞–± 2: –ó–º—ñ–Ω–µ–Ω—ñ —Ñ–∞–π–ª–∏
                with result_tab2:
                    if comparison['modified']:
                        st.subheader("–°–ø–∏—Å–æ–∫ –∑–º—ñ–Ω–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤")
                        for idx, file_path in enumerate(sorted(comparison['modified']), 1):
                            st.text(f"{idx}.")
                            st.code(file_path.replace('/', '\\'), language=None)
                    else:
                        st.info("‚úÖ –ó–º—ñ–Ω–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                
                # –¢–∞–± 3: –í–∏–¥–∞–ª–µ–Ω—ñ —Ñ–∞–π–ª–∏
                with result_tab3:
                    if comparison['deleted']:
                        st.subheader("–°–ø–∏—Å–æ–∫ –≤–∏–¥–∞–ª–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤")
                        for idx, file_path in enumerate(sorted(comparison['deleted']), 1):
                            st.text(f"{idx}.")
                            st.code(file_path.replace('/', '\\'), language=None)
                    else:
                        st.info("‚úÖ –í–∏–¥–∞–ª–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
    elif csv_files and len(csv_files) != 2:
        st.warning(f"‚ö†Ô∏è –ü–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–±—Ä–∞—Ç–∏ —Ä—ñ–≤–Ω–æ 2 —Ñ–∞–π–ª–∏. –ó–∞—Ä–∞–∑ –≤–∏–±—Ä–∞–Ω–æ: {len(csv_files)}")
    else:
        st.info("üëÜ –û–±–µ—Ä—ñ—Ç—å 2 CSV —Ñ–∞–π–ª–∏ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è (–º–æ–∂–Ω–∞ –≤–∏–±—Ä–∞—Ç–∏ –æ–±–∏–¥–≤–∞ –æ–¥–Ω–æ—á–∞—Å–Ω–æ)")

# –§—É—Ç–µ—Ä
st.divider()
